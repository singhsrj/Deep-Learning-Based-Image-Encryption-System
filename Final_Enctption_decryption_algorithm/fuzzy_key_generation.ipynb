{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8efc0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Util.Padding import pad, unpad\n",
    "import galois\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0b2bce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCH parameters: n=255, k=131, t=18 (correctable errors)\n"
     ]
    }
   ],
   "source": [
    "# Using BCH(255, 131) - can correct up to t=18 errors\n",
    "bch = galois.BCH(255, 131)\n",
    "print(f\"BCH parameters: n={bch.n}, k={bch.k}, t={bch.t} (correctable errors)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14fcd309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 6s 0us/step\n",
      "58900480/58889256 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# ----- VGG16 feature extractor -----\n",
    "# Use pretrained VGG16, remove top, global average pooling to get fixed-length vector\n",
    "VGG_INPUT_SHAPE = (224, 224, 3)\n",
    "vgg_model = VGG16(include_top=False, pooling=\"avg\", input_shape=VGG_INPUT_SHAPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f433475",
   "metadata": {},
   "outputs": [],
   "source": [
    "AES_BLOCK_SIZE = 16  # bytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6081d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Helper utilities ----------\n",
    "def load_and_preprocess_image(path, target_size=(224, 224)):\n",
    "    \"\"\"Load image and preprocess for VGG16\"\"\"\n",
    "    img = Image.open(path).convert(\"RGB\").resize(target_size)\n",
    "    arr = np.asarray(img).astype(np.float32)\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    arr = preprocess_input(arr)  # VGG preprocessing\n",
    "    return arr\n",
    "\n",
    "\n",
    "def features_from_image_path(path):\n",
    "    \"\"\"Extract VGG16 features from image\"\"\"\n",
    "    preproc_batch = load_and_preprocess_image(path, target_size=(224, 224))\n",
    "    feats = vgg_model.predict(preproc_batch, verbose=0)[0]  # 1D float vector (512 dims)\n",
    "    return feats\n",
    "\n",
    "\n",
    "def float_features_to_bits(feats, n_bits):\n",
    "    \"\"\"\n",
    "    Convert float feature vector to binary vector of length n_bits\n",
    "    Strategy: min-max normalize -> threshold at 0.5 -> pad/truncate to n_bits\n",
    "    \"\"\"\n",
    "    feats = np.asarray(feats).astype(np.float32)\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    if feats.max() == feats.min():\n",
    "        norm = np.zeros_like(feats)\n",
    "    else:\n",
    "        norm = (feats - feats.min()) / (feats.max() - feats.min())\n",
    "    \n",
    "    # Threshold at 0.5 to get binary\n",
    "    bits = (norm > 0.5).astype(np.uint8).flatten()\n",
    "    \n",
    "    # Pad or truncate to exactly n_bits\n",
    "    if bits.size >= n_bits:\n",
    "        bits = bits[:n_bits]\n",
    "    else:\n",
    "        bits = np.pad(bits, (0, n_bits - bits.size), constant_values=0)\n",
    "    \n",
    "    return bits\n",
    "\n",
    "\n",
    "def bits_to_bytes(bits):\n",
    "    \"\"\"Pack bit array into bytes\"\"\"\n",
    "    return np.packbits(bits).tobytes()\n",
    "\n",
    "\n",
    "def bytes_to_bits(b, n_bits=None):\n",
    "    \"\"\"Unpack bytes to bit array\"\"\"\n",
    "    bits = np.unpackbits(np.frombuffer(b, dtype=np.uint8))\n",
    "    if n_bits is not None:\n",
    "        return bits[:n_bits]\n",
    "    return bits\n",
    "\n",
    "\n",
    "def hamming_distance(bits1, bits2):\n",
    "    \"\"\"Calculate Hamming distance between two bit arrays\"\"\"\n",
    "    return np.sum(np.bitwise_xor(bits1, bits2))\n",
    "\n",
    "\n",
    "# ---------- Fuzzy extractor (Gen / Rep) ----------\n",
    "def enroll(biometric_image_path):\n",
    "    \"\"\"\n",
    "    Enrollment (Gen):\n",
    "    1. Extract VGG16 features from biometric image\n",
    "    2. Binarize to n bits\n",
    "    3. Take first k bits as message, encode with BCH to get n-bit codeword\n",
    "    4. Helper data P = bio_bits XOR codeword\n",
    "    5. Key = SHA-256(codeword)\n",
    "    \n",
    "    Returns: (key_bytes, helper_data_dict, debug_info)\n",
    "    \"\"\"\n",
    "    print(f\"Enrolling with: {biometric_image_path}\")\n",
    "    \n",
    "    # Extract features and binarize\n",
    "    feats = features_from_image_path(biometric_image_path)\n",
    "    bio_bits = float_features_to_bits(feats, n_bits=bch.n)  # length n=255\n",
    "    \n",
    "    # Convert to galois.GF(2) array for BCH encoding\n",
    "    # Message is first k bits\n",
    "    message_bits = bio_bits[:bch.k]  # length k=131\n",
    "    message_gf = galois.GF2(message_bits)\n",
    "    \n",
    "    # BCH encode: message (k bits) -> codeword (n bits)\n",
    "    codeword_gf = bch.encode(message_gf)\n",
    "    codeword = np.array(codeword_gf, dtype=np.uint8)  # length n=255\n",
    "    \n",
    "    print(f\"Message length: {len(message_gf)}, Codeword length: {len(codeword)}\")\n",
    "    \n",
    "    # Helper data: P = bio_bits XOR codeword\n",
    "    P = np.bitwise_xor(bio_bits, codeword).astype(np.uint8)\n",
    "    \n",
    "    # Derive AES key from codeword\n",
    "    codeword_bytes = bits_to_bytes(codeword)\n",
    "    key = hashlib.sha256(codeword_bytes).digest()  # 32 bytes\n",
    "    \n",
    "    helper_data = {\n",
    "        \"P\": P.tolist(),  # store as list for JSON compatibility\n",
    "        \"n\": int(bch.n),\n",
    "        \"k\": int(bch.k),\n",
    "        \"t\": int(bch.t)\n",
    "    }\n",
    "    \n",
    "    debug_info = {\n",
    "        \"enrollment_bio_bits\": bio_bits.copy(),\n",
    "        \"enrollment_codeword\": codeword.copy()\n",
    "    }\n",
    "    \n",
    "    print(f\"Enrollment complete. Key derived (32 bytes)\")\n",
    "    return key, helper_data, debug_info\n",
    "\n",
    "\n",
    "def reproduce_key(biometric_image_path, helper_data, debug_info=None):\n",
    "    \"\"\"\n",
    "    Reproduction (Rep):\n",
    "    1. Extract features from probe biometric\n",
    "    2. Binarize to n bits\n",
    "    3. Compute noisy_codeword = bio_bits_probe XOR P\n",
    "    4. BCH decode to correct errors -> corrected_codeword\n",
    "    5. Key = SHA-256(corrected_codeword)\n",
    "    \n",
    "    Returns: key_bytes (32 bytes), reproduction_debug_info\n",
    "    \"\"\"\n",
    "    print(f\"Reproducing key with: {biometric_image_path}\")\n",
    "    \n",
    "    # Extract features and binarize\n",
    "    feats = features_from_image_path(biometric_image_path)\n",
    "    bio_bits_probe = float_features_to_bits(feats, n_bits=helper_data[\"n\"])\n",
    "    \n",
    "    # Recover helper data\n",
    "    P = np.array(helper_data[\"P\"], dtype=np.uint8)\n",
    "    \n",
    "    # Compute noisy codeword\n",
    "    noisy_codeword = np.bitwise_xor(bio_bits_probe, P).astype(np.uint8)\n",
    "    noisy_codeword_gf = galois.GF2(noisy_codeword)\n",
    "    \n",
    "    # Calculate error statistics if debug info available\n",
    "    repro_debug = {}\n",
    "    if debug_info is not None:\n",
    "        enrollment_bits = debug_info[\"enrollment_bio_bits\"]\n",
    "        bio_hamming = hamming_distance(enrollment_bits, bio_bits_probe)\n",
    "        \n",
    "        enrollment_codeword = debug_info[\"enrollment_codeword\"]\n",
    "        codeword_hamming = hamming_distance(enrollment_codeword, noisy_codeword)\n",
    "        \n",
    "        repro_debug[\"bio_hamming_distance\"] = int(bio_hamming)\n",
    "        repro_debug[\"noisy_codeword_hamming\"] = int(codeword_hamming)\n",
    "        \n",
    "        print(f\"Biometric Hamming distance: {bio_hamming}/{helper_data['n']} bits\")\n",
    "        print(f\"Noisy codeword errors: {codeword_hamming}/{helper_data['n']} bits (max correctable: {helper_data['t']})\")\n",
    "    \n",
    "    # BCH decode to correct errors\n",
    "    try:\n",
    "        corrected_gf = bch.decode(noisy_codeword_gf)\n",
    "        corrected = np.array(corrected_gf, dtype=np.uint8)\n",
    "        print(f\"BCH decoding successful\")\n",
    "        repro_debug[\"decode_success\"] = True\n",
    "    except Exception as e:\n",
    "        repro_debug[\"decode_success\"] = False\n",
    "        repro_debug[\"error\"] = str(e)\n",
    "        raise ValueError(f\"BCH decode failed - too many bit errors (>{helper_data['t']}): {e}\")\n",
    "    \n",
    "    # Derive AES key from corrected codeword\n",
    "    corrected_bytes = bits_to_bytes(corrected)\n",
    "    key = hashlib.sha256(corrected_bytes).digest()\n",
    "    \n",
    "    print(f\"Key reproduced successfully (32 bytes)\")\n",
    "    return key, repro_debug\n",
    "\n",
    "\n",
    "# ---------- AES encrypt/decrypt helpers (AES-CBC) ----------\n",
    "def aes_cbc_encrypt_numpy_array(np_array_uint8, key_bytes):\n",
    "    \"\"\"\n",
    "    Encrypt numpy array (uint8) with AES-CBC\n",
    "    Returns: (ciphertext, iv, metadata)\n",
    "    \"\"\"\n",
    "    plaintext = np_array_uint8.tobytes()\n",
    "    cipher = AES.new(key_bytes, AES.MODE_CBC)\n",
    "    iv = cipher.iv\n",
    "    ct = cipher.encrypt(pad(plaintext, AES_BLOCK_SIZE))\n",
    "    \n",
    "    meta = {\n",
    "        \"shape\": list(np_array_uint8.shape),\n",
    "        \"dtype\": str(np_array_uint8.dtype)\n",
    "    }\n",
    "    return ct, iv, meta\n",
    "\n",
    "\n",
    "def aes_cbc_decrypt_to_numpy(ciphertext, iv, key_bytes, meta):\n",
    "    \"\"\"\n",
    "    Decrypt AES-CBC ciphertext to numpy array\n",
    "    \"\"\"\n",
    "    cipher = AES.new(key_bytes, AES.MODE_CBC, iv=iv)\n",
    "    pt_padded = cipher.decrypt(ciphertext)\n",
    "    pt = unpad(pt_padded, AES_BLOCK_SIZE)\n",
    "    \n",
    "    arr = np.frombuffer(pt, dtype=np.dtype(meta[\"dtype\"]))\n",
    "    arr = arr.reshape(tuple(meta[\"shape\"]))\n",
    "    return arr\n",
    "\n",
    "\n",
    "# ---------- High-level pipeline functions ----------\n",
    "def encrypt_image_with_biometric(image_to_encrypt_path, biometric_image_path):\n",
    "    \"\"\"\n",
    "    Full encryption pipeline:\n",
    "    1. Load image to encrypt\n",
    "    2. Enroll biometric -> derive AES key + helper data\n",
    "    3. Encrypt image with AES-CBC\n",
    "    \n",
    "    Returns: cipher_bundle dict\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== ENCRYPTION ===\")\n",
    "    print(f\"Image to encrypt: {image_to_encrypt_path}\")\n",
    "    \n",
    "    # Load image to encrypt\n",
    "    img = Image.open(image_to_encrypt_path).convert(\"RGB\")\n",
    "    arr = np.asarray(img).astype(np.uint8)\n",
    "    print(f\"Image shape: {arr.shape}\")\n",
    "    \n",
    "    # Enroll biometric and derive key\n",
    "    key, helper_data, debug_info = enroll(biometric_image_path)\n",
    "    \n",
    "    # Encrypt with AES-CBC\n",
    "    ct, iv, meta = aes_cbc_encrypt_numpy_array(arr, key)\n",
    "    print(f\"Encryption complete. Ciphertext size: {len(ct)} bytes\")\n",
    "    \n",
    "    return {\n",
    "        \"ciphertext\": ct,\n",
    "        \"iv\": iv,\n",
    "        \"helper_data\": helper_data,\n",
    "        \"meta\": meta,\n",
    "        \"debug_info\": debug_info\n",
    "    }\n",
    "\n",
    "\n",
    "def decrypt_image_with_biometric(cipher_bundle, biometric_probe_path):\n",
    "    \"\"\"\n",
    "    Full decryption pipeline:\n",
    "    1. Reproduce key from probe biometric + helper data\n",
    "    2. Decrypt with AES-CBC\n",
    "    \n",
    "    Returns: recovered numpy array (uint8), reproduction_debug_info\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== DECRYPTION ===\")\n",
    "    \n",
    "    helper_data = cipher_bundle[\"helper_data\"]\n",
    "    ct = cipher_bundle[\"ciphertext\"]\n",
    "    iv = cipher_bundle[\"iv\"]\n",
    "    meta = cipher_bundle[\"meta\"]\n",
    "    debug_info = cipher_bundle.get(\"debug_info\", None)\n",
    "    \n",
    "    # Reproduce key from biometric probe\n",
    "    key_reproduced, repro_debug = reproduce_key(biometric_probe_path, helper_data, debug_info)\n",
    "    \n",
    "    # Decrypt\n",
    "    arr = aes_cbc_decrypt_to_numpy(ct, iv, key_reproduced, meta)\n",
    "    print(f\"Decryption complete. Recovered shape: {arr.shape}\")\n",
    "    \n",
    "    return arr, repro_debug\n",
    "\n",
    "\n",
    "# ---------- Storage functions ----------\n",
    "def save_cipher_bundle(bundle, filepath=\"cipher_bundle.pkl\"):\n",
    "    \"\"\"Save cipher bundle to file (pickle for binary data)\"\"\"\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(bundle, f)\n",
    "    print(f\"Cipher bundle saved to: {filepath}\")\n",
    "\n",
    "\n",
    "def load_cipher_bundle(filepath=\"cipher_bundle.pkl\"):\n",
    "    \"\"\"Load cipher bundle from file\"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        bundle = pickle.load(f)\n",
    "    print(f\"Cipher bundle loaded from: {filepath}\")\n",
    "    return bundle\n",
    "\n",
    "\n",
    "def save_helper_data_json(helper_data, filepath=\"helper_data.json\"):\n",
    "    \"\"\"Save just the helper data as JSON (public data)\"\"\"\n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(helper_data, f, indent=2)\n",
    "    print(f\"Helper data saved to: {filepath}\")\n",
    "\n",
    "\n",
    "def load_helper_data_json(filepath=\"helper_data.json\"):\n",
    "    \"\"\"Load helper data from JSON\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        helper_data = json.load(f)\n",
    "    print(f\"Helper data loaded from: {filepath}\")\n",
    "    return helper_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b016805",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a551bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ---------- Testing and analysis functions ----------\n",
    "def test_biometric_pair(bio_path1, bio_path2, test_name=\"Test\"):\n",
    "    \"\"\"\n",
    "    Test a pair of biometric images to see if they can reproduce the same key\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{test_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Enroll with first image\n",
    "    key1, helper_data, debug_info = enroll(bio_path1)\n",
    "    \n",
    "    # Try to reproduce with second image\n",
    "    try:\n",
    "        key2, repro_debug = reproduce_key(bio_path2, helper_data, debug_info)\n",
    "        \n",
    "        # Check if keys match\n",
    "        keys_match = (key1 == key2)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"RESULT: {'✓ SUCCESS' if keys_match else '✗ FAILURE'}\")\n",
    "        print(f\"Keys match: {keys_match}\")\n",
    "        print(f\"Bio Hamming distance: {repro_debug.get('bio_hamming_distance', 'N/A')}/{bch.n}\")\n",
    "        print(f\"Noisy codeword errors: {repro_debug.get('noisy_codeword_hamming', 'N/A')}/{bch.n}\")\n",
    "        print(f\"Max correctable errors: {bch.t}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        return keys_match, repro_debug\n",
    "        \n",
    "    except ValueError as e:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"RESULT: ✗ FAILURE\")\n",
    "        print(f\"Error: {e}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        return False, {\"error\": str(e)}\n",
    "\n",
    "\n",
    "def analyze_feature_similarity(bio_path1, bio_path2):\n",
    "    \"\"\"\n",
    "    Analyze similarity between two biometric images at feature level\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Feature Similarity Analysis ===\")\n",
    "    print(f\"Image 1: {bio_path1}\")\n",
    "    print(f\"Image 2: {bio_path2}\")\n",
    "    \n",
    "    # Extract features\n",
    "    feats1 = features_from_image_path(bio_path1)\n",
    "    feats2 = features_from_image_path(bio_path2)\n",
    "    \n",
    "    # Feature-level statistics\n",
    "    cosine_sim = np.dot(feats1, feats2) / (np.linalg.norm(feats1) * np.linalg.norm(feats2))\n",
    "    l2_distance = np.linalg.norm(feats1 - feats2)\n",
    "    \n",
    "    # Bit-level statistics\n",
    "    bits1 = float_features_to_bits(feats1, n_bits=bch.n)\n",
    "    bits2 = float_features_to_bits(feats2, n_bits=bch.n)\n",
    "    hamming_dist = hamming_distance(bits1, bits2)\n",
    "    hamming_ratio = hamming_dist / bch.n\n",
    "    \n",
    "    print(f\"Feature dimension: {len(feats1)}\")\n",
    "    print(f\"Cosine similarity: {cosine_sim:.4f}\")\n",
    "    print(f\"L2 distance: {l2_distance:.4f}\")\n",
    "    print(f\"Hamming distance: {hamming_dist}/{bch.n} ({hamming_ratio*100:.2f}%)\")\n",
    "    print(f\"BCH can correct: up to {bch.t} errors ({bch.t/bch.n*100:.2f}%)\")\n",
    "    print(f\"Status: {'Within correction capability' if hamming_dist <= bch.t else 'Exceeds correction capability'}\")\n",
    "    \n",
    "    return {\n",
    "        \"cosine_similarity\": float(cosine_sim),\n",
    "        \"l2_distance\": float(l2_distance),\n",
    "        \"hamming_distance\": int(hamming_dist),\n",
    "        \"hamming_ratio\": float(hamming_ratio),\n",
    "        \"correctable\": hamming_dist <= bch.t\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf4bf8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "567ad019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Biometric Fuzzy Extractor with BCH + AES\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "PART 1: Analyzing Biometric Similarity\n",
      "============================================================\n",
      "\n",
      "=== Feature Similarity Analysis ===\n",
      "Image 1: biometric images/kelvinl3.jpg\n",
      "Image 2: biometric images/kelvinl5.jpg\n",
      "Feature dimension: 512\n",
      "Cosine similarity: 0.9506\n",
      "L2 distance: 27.3689\n",
      "Hamming distance: 4/255 (1.57%)\n",
      "BCH can correct: up to 18 errors (7.06%)\n",
      "Status: Within correction capability\n",
      "\n",
      "============================================================\n",
      "PART 2: Testing Key Reproduction\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Same Person Test (kelvinl3 vs kelvinl5)\n",
      "============================================================\n",
      "Enrolling with: biometric images/kelvinl3.jpg\n",
      "Message length: 131, Codeword length: 255\n",
      "Enrollment complete. Key derived (32 bytes)\n",
      "Reproducing key with: biometric images/kelvinl5.jpg\n",
      "Biometric Hamming distance: 4/255 bits\n",
      "Noisy codeword errors: 4/255 bits (max correctable: 18)\n",
      "BCH decoding successful\n",
      "Key reproduced successfully (32 bytes)\n",
      "\n",
      "============================================================\n",
      "RESULT: ✗ FAILURE\n",
      "Keys match: False\n",
      "Bio Hamming distance: 4/255\n",
      "Noisy codeword errors: 4/255\n",
      "Max correctable errors: 18\n",
      "============================================================\n",
      "\n",
      "\n",
      "============================================================\n",
      "PART 3: Full Encryption/Decryption Pipeline\n",
      "============================================================\n",
      "\n",
      "=== ENCRYPTION ===\n",
      "Image to encrypt: image.jpg\n",
      "Image shape: (128, 128, 3)\n",
      "Enrolling with: biometric images/kelvinl3.jpg\n",
      "Message length: 131, Codeword length: 255\n",
      "Enrollment complete. Key derived (32 bytes)\n",
      "Encryption complete. Ciphertext size: 49168 bytes\n",
      "Cipher bundle saved to: cipher_bundle.pkl\n",
      "Helper data saved to: helper_data.json\n",
      "\n",
      "=== DECRYPTION ===\n",
      "Reproducing key with: biometric images/kelvinl5.jpg\n",
      "Biometric Hamming distance: 4/255 bits\n",
      "Noisy codeword errors: 4/255 bits (max correctable: 18)\n",
      "BCH decoding successful\n",
      "Key reproduced successfully (32 bytes)\n",
      "\n",
      "✗ DECRYPTION FAILED: Padding is incorrect.\n",
      "The probe biometric differs too much from enrollment.\n",
      "BCH can correct up to 18 bit errors out of 255 bits.\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "BCH Code: BCH(255, 131) with t=18 error correction\n",
      "Feature Extractor: VGG16 (512-dim features)\n",
      "Encryption: AES-256-CBC\n",
      "Key Derivation: SHA-256(BCH_codeword)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ---------- Main execution ----------\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths\n",
    "    biometric_enroll = \"biometric images/kelvinl3.jpg\"   # enrollment biometric\n",
    "    biometric_probe = \"biometric images/kelvinl5.jpg\"     # probe biometric (same person)\n",
    "    image_to_encrypt = \"image.jpg\"                        # image to encrypt\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Biometric Fuzzy Extractor with BCH + AES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # ========== PART 1: Feature Analysis ==========\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PART 1: Analyzing Biometric Similarity\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if os.path.exists(biometric_enroll) and os.path.exists(biometric_probe):\n",
    "        similarity_stats = analyze_feature_similarity(biometric_enroll, biometric_probe)\n",
    "    else:\n",
    "        print(f\"Warning: Biometric files not found. Skipping similarity analysis.\")\n",
    "    \n",
    "    # ========== PART 2: Key Reproduction Test ==========\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PART 2: Testing Key Reproduction\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if os.path.exists(biometric_enroll) and os.path.exists(biometric_probe):\n",
    "        success, debug = test_biometric_pair(biometric_enroll, biometric_probe, \n",
    "                                             \"Same Person Test (kelvinl3 vs kelvinl5)\")\n",
    "    else:\n",
    "        print(f\"Warning: Biometric files not found. Skipping key reproduction test.\")\n",
    "    \n",
    "    # ========== PART 3: Full Encrypt/Decrypt Pipeline ==========\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PART 3: Full Encryption/Decryption Pipeline\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if not os.path.exists(image_to_encrypt):\n",
    "        print(f\"Warning: Image to encrypt '{image_to_encrypt}' not found.\")\n",
    "        print(\"Skipping encryption/decryption demo.\")\n",
    "    elif not os.path.exists(biometric_enroll) or not os.path.exists(biometric_probe):\n",
    "        print(f\"Warning: Biometric images not found.\")\n",
    "        print(\"Skipping encryption/decryption demo.\")\n",
    "    else:\n",
    "        # STEP 1: ENROLL + ENCRYPT\n",
    "        bundle = encrypt_image_with_biometric(image_to_encrypt, biometric_enroll)\n",
    "        \n",
    "        # Save bundle to disk\n",
    "        save_cipher_bundle(bundle, \"cipher_bundle.pkl\")\n",
    "        save_helper_data_json(bundle[\"helper_data\"], \"helper_data.json\")\n",
    "        \n",
    "        # STEP 2: DECRYPT using probe biometric\n",
    "        try:\n",
    "            recovered, repro_debug = decrypt_image_with_biometric(bundle, biometric_probe)\n",
    "            \n",
    "            # Save recovered image\n",
    "            recovered_img = Image.fromarray(recovered)\n",
    "            recovered_img.save(\"recovered.png\")\n",
    "            \n",
    "            # Verify recovery\n",
    "            original_img = Image.open(image_to_encrypt).convert(\"RGB\")\n",
    "            original_arr = np.asarray(original_img)\n",
    "            \n",
    "            if np.array_equal(original_arr, recovered):\n",
    "                print(f\"\\n✓ PERFECT RECOVERY: Image matches original exactly!\")\n",
    "            else:\n",
    "                diff = np.sum(np.abs(original_arr.astype(int) - recovered.astype(int)))\n",
    "                print(f\"\\n⚠ IMPERFECT RECOVERY: Total pixel difference = {diff}\")\n",
    "            \n",
    "            print(f\"✓ Recovered image saved to 'recovered.png'\")\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(f\"\\n✗ DECRYPTION FAILED: {e}\")\n",
    "            print(\"The probe biometric differs too much from enrollment.\")\n",
    "            print(f\"BCH can correct up to {bch.t} bit errors out of {bch.n} bits.\")\n",
    "    \n",
    "    # ========== PART 4: Summary ==========\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"BCH Code: BCH({bch.n}, {bch.k}) with t={bch.t} error correction\")\n",
    "    print(f\"Feature Extractor: VGG16 (512-dim features)\")\n",
    "    print(f\"Encryption: AES-256-CBC\")\n",
    "    print(f\"Key Derivation: SHA-256(BCH_codeword)\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a8ab3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
